{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"GPTQuery Documentation","text":"<p>Welcome to GPTQuery \u2014 a modular framework for AI-powered tool orchestration.</p>"},{"location":"#structure","title":"Structure","text":"<ul> <li>Quickstart \u2192 docs/quickstart.md</li> <li>Developer Guide \u2192 docs/devsquickstart.md</li> <li>Architecture \u2192 docs/architecture.md</li> <li>Tools \u2192 docs/tools/</li> </ul> Tip for Devs <p>I recommend you install the package from the source instead of from <code>PyPI</code> using pip since the most up to date, and developing tools requires you to have access to the source code anyways to add your own tool.</p>"},{"location":"advanced_usage/","title":"\u2697\ufe0f Advanced Usage","text":"<p>When you create a new tool you should make a function <code>*_basic()</code> that has all the presets required making the tool call work following default settings. However, for testing purposes or for custom pipelines you should be able to use the <code>run_*</code> function. This set-up affords flexibility and ease for both basic and power users as the basic is just a wrapper with defaults for the base main run fucntion.</p>"},{"location":"advanced_usage/#multi-provider-tool-calls","title":"\ud83d\udd00 Multi-Provider Tool Calls","text":"<pre><code># OpenAI GPT-4\nresult_openai = run_validate_basic(df, \n                                  openai_key, \n                                  provider=\"openai\", \n                                  model=\"gpt-4o\")\n\n# Perplexity Sonar\nresult_perplexity = run_validate_basic(df, \n                                      perplexity_key, \n                                      provider=\"perplexity\", \n                                      model=\"sonar-pro\")\n\n# Claude 3.5 Sonnet  \nresult_claude = run_validate_basic(df, \n                                  claude_key, \n                                  provider=\"claude\", \n                                  model=\"claude-3-5-sonnet-20241022\")\n</code></pre> <pre><code># RUN using perplexity with online search capability\ndf_pplx = run_validate(\n          df,\n          prompt_func=prompt_validate_completeness,\n          api_key=\"your-perplexity-key\", \n          provider=\"perplexity\",\n          model=\"llama-3.1-sonar-large-128k-online\",  # Real-time web search\n          granularity=\"full\")\ndf_pplx\n</code></pre>"},{"location":"advanced_usage/#custom-throttling-configuration","title":"Custom Throttling Configuration","text":"<pre><code>from processing.throttling import TokenBucketThrottler\nfrom gptquery.tools.tool_eulaw_citations import run_extract\nfrom gptquery.tools.tool_eulaw_citations.extract_citations.prompts.default import (prompt_extract_basic)\n\n# OpenAI with custom throttling\nthrottler = TokenBucketThrottler(rpm=30)\n\ndf_out = run_extract(\n         df,\n         prompt_func=prompt_validate_completeness,\n         api_key=\"your-openai-key\",\n         provider=\"openai\",\n         throttler=throttler,\n         model=\"gpt-4.1-mini\",\n         granularity=\"article\",\n         progress=True )\ndf_out\n</code></pre>"},{"location":"architecture/","title":"Project Architecture","text":""},{"location":"architecture/#gptquery-architecture","title":"GPTQuery Architecture","text":"<pre><code>gptquery/                      \n\u251c\u2500\u2500 __init__.py                # Core package exports (e.g., GPTClient)\n\u2502\n\u251c\u2500\u2500 core/                      \n\u2502   \u251c\u2500\u2500 __init__.py            \n\u2502   \u251c\u2500\u2500 client.py              \n\u2502   \u2514\u2500\u2500 execution_logger.py    \n\u2502\n\u251c\u2500\u2500 estimation/                \n\u2502   \u251c\u2500\u2500 __init__.py            \n\u2502   \u251c\u2500\u2500 cost_estimator.py      \n\u2502   \u251c\u2500\u2500 prompt_generator.py    \n\u2502   \u2514\u2500\u2500 tokens.py              \n\u2502\n\u251c\u2500\u2500 processing/                \n\u2502   \u251c\u2500\u2500 __init__.py            \n\u2502   \u251c\u2500\u2500 throttling.py          \n\u2502   \u2514\u2500\u2500 utils.py               \n\u2502\n\u251c\u2500\u2500 tools/                     \n\u2502   \u251c\u2500\u2500 __init__.py            # Exposes top-level tools (aliases)\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 tool_eulaw_citations/  # Unified EU law citations tool\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py        # Exports main public API\n\u2502   \u2502   \u251c\u2500\u2500 validate_citations/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 task.py        # run_validate_basic\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 log.py\n\u2502   \u2502   \u251c\u2500\u2500 extract_citations/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 task.py        # run_extract_basic\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 log.py\n\u2502   \u2502   \u2514\u2500\u2500 select_citations/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 task.py        # run_select_basic\n\u2502   \u2502       \u251c\u2500\u2500 prompt.py\n\u2502   \u2502       \u2514\u2500\u2500 log.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 future_tool_one/       # Future tool #1\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py        # Exports main public API for this tool\n\u2502   \u2502   \u251c\u2500\u2500 step_a/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 task.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 log.py\n\u2502   \u2502   \u2514\u2500\u2500 step_b/\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 task.py\n\u2502   \u2502       \u251c\u2500\u2500 prompt.py\n\u2502   \u2502       \u2514\u2500\u2500 log.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 future_tool_two/       # Future tool #2\n\u2502       \u251c\u2500\u2500 __init__.py        # Exports main public API for this tool\n\u2502       \u251c\u2500\u2500 step_x/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 task.py\n\u2502       \u2502   \u251c\u2500\u2500 prompt.py\n\u2502       \u2502   \u2514\u2500\u2500 log.py\n\u2502       \u2514\u2500\u2500 step_y/\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u251c\u2500\u2500 task.py\n\u2502           \u251c\u2500\u2500 prompt.py\n\u2502           \u2514\u2500\u2500 log.py\n\u2502\n\u2514\u2500\u2500 utils/                     \n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 data_prep.py           # Data preparation modules\n    \u2514\u2500\u2500 (other utility modules)\n</code></pre>"},{"location":"architecture/#project-docs-structure","title":"Project &amp; Docs Structure","text":"<pre><code>gptquery/\n\u251c\u2500\u2500 gptquery/              # source code\n\u251c\u2500\u2500 docs/                  # \u2190 documentation lives here\n\u2502   \u251c\u2500\u2500 index.md           # main README-style overview\n\u2502   \u251c\u2500\u2500 quickstart.md      # install &amp; run examples\n\u2502   \u251c\u2500\u2500 architecture.md    # how modules &amp; layers fit together\n\u2502   \u251c\u2500\u2500 tools/             # per-tool docs (optional, auto-generated later)\n\u2502   \u2502   \u251c\u2500\u2500 eulaw_citations.md\n\u2502   \u2502   \u2514\u2500\u2500 future_tool_one.md\n\u2502   \u2514\u2500\u2500 api_reference.md   # short docstrings export\n\u251c\u2500\u2500 README.md              # landing summary\n\u251c\u2500\u2500 LICENSE\n\u2514\u2500\u2500 pyproject.toml\n</code></pre>"},{"location":"devsquickstart/","title":"Developers Guide","text":"<p>This guide is inteded for users that want to create their own AI-power reserach tools. It will walk you through the basic components of this package and how to structure your own tool so that it can be succesully deployed in the main package API.</p>"},{"location":"devsquickstart/#clone-the-gptquery-project","title":"\ud83d\udce5 Clone the gptquery Project","text":"<p>Clone the repository to build custom tools based on GPTQuery, clone the repo and install dependencies:</p> <pre><code># 1. Clone the repo:\ngit clone https://github.com/mauriciomm7/gptquery.git\ncd gptquery\n# 2. Install as editable package:\npip install -e .\n</code></pre>"},{"location":"devsquickstart/#building-blocks","title":"\ud83e\uddf1 Building Blocks","text":"<p>The building blocks of this package are three: 1) <code>GPTClient()</code>, 2) <code>Throttler()</code>, 3) <code>ExecutionLogger()</code>.</p>"},{"location":"devsquickstart/#gptclient","title":"GPTClient","text":"<p>The GPTClient class is the core interface for interacting with multiple GPT-based API providers (currently supporting OpenAI, Perplexity, and Claude). It standardizes the process of sending and receiving chat completions across different APIs, handling authentication, model validation, request formatting, retries, and error management under a unified abstraction.</p> <p>The logic of this GPTClient is that you initialize it with the parameters you want, and once you\u2019ve done so, you can run queries repeatedly using the same configuration \u2014 without needing to reauthenticate, reselect the provider, or redefine the model each time.</p> <pre><code>from gptquery.core import GPTClient\n# 1. Initialize a client \nclient = GPTClient(api_key=\"sk-123\", \n                   provider=\"openai\", \n                   default_model=\"gpt-4.1-mini\")\n\n# 2. Loop through list of items\nfor user_message in texts:\n    result = client.extract(\n                text=user_message,           # User message (dynamic question data)\n                prompt=system_message)       # System message (static instructions)\n</code></pre> <p>Without persistent initialization, you\u2019d be rebuilding all headers and configs per iteration \u2014 inefficient and more likely to trigger rate limits.</p>"},{"location":"devsquickstart/#throttler","title":"Throttler","text":"<p>Now, that you can now run many queries using a basic loop, you may still want to run them in paralell but without hitting any of the tokens per minute (TKM), or requests per minute (RPM). Here is where the Throttler functions come in handy. In this package there are three but for simplicity I will showcase <code>SimpleThrottler()</code> as is enough for most scenarios.</p> <pre><code>from gptquery.core import GPTClient\nfrom gptquery.processing import GPTClient\n\n# Initialize the GPT client\nclient = GPTClient(model=\"gpt-4.1-mini\", temperature=0)\n\n# Initialize a simple throttler to control request rate\nthrottler = SimpleThrottler(max_requests_per_minute=60)\n\n# Example list of prompts\nprompts = [] # &lt;-- Assume list of prompts\nresults = []\nfor prompt in prompts:\n    throttler.wait_for_slot()  # ENSURES we stay within rate limits\n    result = client.query(prompt)\n    results.append(result)\n</code></pre>"},{"location":"devsquickstart/#executionlogger","title":"ExecutionLogger","text":"<p>Unlike the first two components, <code>ExecutionLogger</code> focuses on logging the execution details of your tools. It saves structured JSON logs to a <code>logs/</code> directory in the user\u2019s working folder, useful for auditing, debugging, and transparency.</p> <pre><code>from gptquery.core.execution_logger import ExecutionLogger\n\nclass ToolLogger(ExecutionLogger):\n    def __init__(self):\n        super().__init__(\"tool_name\")\n\n    def log_execution(self, func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            start = time.time()\n            result = func(*args, **kwargs)\n            duration = time.time() - start\n            self.save_execution_log({\"execution_time\": duration})\n            return result\n        return wrapper\n</code></pre> <p>Then once you built the tool-specific logging class you can add it as a decorator class for every time you run the class.</p> <pre><code># Initialize the ToolLogger\nlogger = ToolLogger()\n\n@logger.log_execution\ndef my_function(data):\n    # Your processing here\n    return data\n</code></pre>"},{"location":"devsquickstart/#creating-an-ai-powered-tool","title":"\ud83d\udd28 Creating an AI-Powered Tool","text":"<p>Under the project dir you will find a <code>tools/</code> directory which is where the GPI Tools live. These task-specific tools have the following structure:</p> <ul> <li>Task-Specific Tools (<code>tools/</code>)</li> <li>Each tool lives in its own namespace (e.g., <code>tool_name</code>).  </li> <li>Tools are subdivided into submodules/steps:<ul> <li><code>prompt.py</code> \u2192 AI prompt definitions</li> <li><code>task.py</code> \u2192 user-facing functions (<code>run_*</code>)  </li> <li><code>log.py</code> \u2192 logging utilities  </li> </ul> </li> <li>The tool\u2019s <code>__init__.py</code> exposes the main public API.</li> </ul>"},{"location":"devsquickstart/#promptpy","title":"<code>prompt.py</code>","text":"<p>The first step in creating a tool is to createa a <code>prompt.py</code>. This will contain the prompt constructor fucntion and system prompt. The prompt constructor will take text specific paramentes that will be used to generate the <code>user_msg</code>. You can think of these paramters as the columns from a dataframe entry. When building this fucntion you can pass the <code>@requires_columns()</code> decorator to make sure that when you call the fucntion it receives the correct parameters. When building this function, you can apply the @requires_columns() decorator to ensure it receives the correct parameters when called. This is important because it guarantees that the tool call follows a contract by requiring all necessary inputs, preventing runtime errors and ensuring consistent behavior.</p> <pre><code># tool_name/step_one/prompt.py\n\n@requires_columns(\"first_page_text\")\ndef prompt_extract_affiliations(first_page_text: str) -&gt; str:\n    user_message = f\"\"\"TEXT TO ANALYZE:\n{first_page_text}\n\nEXTRACTION TASK: Extract all institutions or organizations associated with the authors. \nInclude universities, ministries, commissions, research institutes, or other organizations. \nSeparate each institution with a comma. Ignore faculties, departments, research groups, addresses, or individual offices.\"\"\"\n    return user_message.strip()\n</code></pre> <p>The static system message is <code>system_message</code></p> <pre><code># tool_name/step_one/prompt.py\nSYSTEM_MSG = \"\"\"\nThis is is the static message that will be passes as system_message for every call.\nYou can use multiline formatting as long as you use the triple quotation marks.\n\nAnd even add '\\n' new lines directly.\n\"\"\"\n</code></pre>"},{"location":"devsquickstart/#taskpy","title":"<code>task.py</code>","text":""},{"location":"devsquickstart/#logpy","title":"<code>log.py</code>","text":""},{"location":"quickstart/","title":"Quick Start","text":"<p>The goal of this package is to enable reserachers (or anyone) to create tractable AI tools that were used in for preocessing the data of any research paper. This quickstart guide is inteded for end-users of these tools. If you wnat to create your own tool check out developers guide.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>Install the latest stable release directly from PyPI using pip:</p> <pre><code>pip install gptquerytools\n</code></pre>"},{"location":"quickstart/#authentication","title":"\ud83d\udd11 Authentication","text":"<p>Use python-dotenv (Python) to load the environment variable from a .env file:</p> <pre><code>from pathlib import Path\nfrom dotenv import load_dotenv\n\n# LOAD environment variables from &lt;name&gt;.env file\nSECRETS_FILE = Path(r\"C:\\LocalSecrets\\master.env\")\nload_dotenv(str(SECRETS_FILE))\n\n# ASSIGN the values of the environment variables\nopenai_key = str(os.getenv(\"OPENAI_UIO24EMC_KEY\"))\n</code></pre> <p>Now everytime you make a tool call you just have to provide the api key that you want to use.</p>"},{"location":"quickstart/#1-eu-law-citations-proccessing","title":"\ud83c\udfae 1. EU Law Citations Proccessing","text":"<p>The following examples correspond to the EU Law Citations Tools. For full details see full docs.</p> <ul> <li>Example 1: Validate whether all in-text citations from <code>question_text</code> are in <code>potential_citations</code>:</li> </ul> <pre><code>from gptquery import run_validate_basic\nnew_validate_df = run_validate_basic(df_validation, \n                                     api_key=openai_key, \n                                     model=\"gpt-4.1-mini\")\nprint(new_validate_df['is_complete'])  \n&gt;&gt;&gt; # RESULT Dataframe new col:\n&gt;&gt;&gt; [[\"complete\"], [\"incomplete\"], [\"ERROR\"]]\n</code></pre> <ul> <li>Example 2: Extract missing in-text citations from <code>question_text</code> that are NOT listed in <code>potential_citations</code>:</li> </ul> <pre><code>from gptquery import run_extract_basic\ndf_out = run_extract_basic(df_validation,\n                           api_key=openai_key, \n                           model=\"gpt-4.1-mini\"))\nprint(df_out['missing_citations'])\n&gt;&gt;&gt; # Result DataFrame has new 'missing_citations' column:\n&gt;&gt;&gt; [[], [\"citation1\"], [\"citation1\", \"citation2\"], [\"ERROR\"]]\n</code></pre>"},{"location":"quickstart/#2-text-extracting-tools","title":"\ud83c\udfae 2. Text Extracting Tools","text":""},{"location":"quickstart/#cost-estimation-utilities","title":"\ud83d\udcb0 Cost Estimation Utilities","text":""},{"location":"tools/eulaw_citations/","title":"EU Law Citations Processing","text":"<p>This set of tools were created to extract EU Law citations from text following a standarized approach. It works best when you first scrape citations from metadata and provide them as a baseline for the LLM to extract them.</p>"},{"location":"tools/eulaw_citations/#basic-usage-description","title":"Basic Usage Description","text":""},{"location":"tools/eulaw_citations/#validate-whether-all-in-text-citations-are-listed","title":"\ud83d\udd27 VALIDATE whether all in-text citations are listed","text":"<p>The first tool, <code>run_validate_basic()</code>, expects a text column (<code>question_text</code>) that may contain in-text EU law citations, and separately, a single string listing all citations (<code>potential_citations</code>). For each row, the function combines the text with this list of citations to create the user message (<code>user_msg</code>). Using these dynamic user messages and a tool-specific system prompt, it determines whether any citations are missing or if all are covered by the provided list.</p> <pre><code>from gptquery.tools.tool_eulaw_citations import run_validate_basic\ndf = ...  # DataFrame with 'question_text' and 'potential_citations'\ndf_out = run_validate_basic(df, api_key=\"your-openai-key\")\nprint(df_out['is_complete'])  # \"complete\" or \"incomplete\"\n</code></pre>"},{"location":"tools/eulaw_citations/#extract-eu-law-in-text-citations","title":"\ud83d\udd27 EXTRACT EU Law in-text citations","text":"<p>The second tool is <code>run_extract_basic()</code> which expects that you provide a text column (<code>question_text</code>) where there may be in-text EU Law citations and separately, as a single string, a list of all citations (<code>potential_citations</code>). For each row, the prompt function combines the text of <code>question_text</code> with this list of citations to make the user message <code>user_msg</code>.</p> <pre><code>from gptquery.tools.tool_eulaw_citations import run_extract_basic\ndf = ...  # DataFrame with 'question_text' and 'potential_citations'\ndf_out = run_extract_basic(df, api_key=\"your-openai-key\")\nprint(df['missing_citations']) \n&gt;&gt;&gt; #Result DataFrame has new 'missing_citations' column:\n&gt;&gt;&gt; [[], [\"citation1\"], [\"citation1\", \"citation2\"], [\"ERROR\"]]\n</code></pre> <p>For this tool you can specify the level fo granularity to either:</p> <ul> <li><code>\"full\"</code> \u2013 Only check if the instrument is cited</li> <li><code>\"article\"</code> \u2013 Must match article numbers</li> <li><code>\"paragraph\"</code> \u2013 Must match paragraphs and points</li> </ul> <pre><code>df_out = run_extract_basic(df, \n                            api_key=\"your-openai-key\", \n                            granularity=\"article\")\nprint(df['missing_citations']) \n#Result DataFrame has new 'missing_citations' column:\n&gt;&gt;&gt; [[], [\"citation1\"], [\"citation1\", \"citation2\"], [\"ERROR\"]]\n</code></pre>"},{"location":"tools/eulaw_citations/#select-eu-law-in-text-citations","title":"\ud83d\udd27 SELECT EU Law in-text citations","text":"<pre><code>from gptquery.tools.tool_eulaw_citations import run_select_basic\ndf = ...  # DataFrame with 'question_text' and 'potential_citations'\ndf_result = run_select_basic(df, \"openai-api-key\")\n# Result DataFrame has new 'selected_citations' column:\n&gt;&gt;&gt; [[], [\"citation1\"], [\"citation1\", \"citation2\"], [\"ERROR\"]]\n</code></pre>"},{"location":"tools/eulaw_citations/#inputoutput-schema","title":"\ud83d\udce4 Input/Output Schema","text":"<p>All the tools </p> <p>Input Columns:</p> Column Type Description <code>question_text</code> str The legal question to analyze <code>potential_citations</code> str Newline-separated CELEX-format citations <p>Output Columns:</p> <ul> <li><code>is_complete</code> \u2192 \"complete\" or \"incomplete\"</li> <li><code>missing_citations</code> \u2192 list of citation strings</li> <li><code>selected_citations</code> \u2192 list of citation IDs</li> </ul>"},{"location":"tools/eulaw_citations/#example-dataframe","title":"\ud83d\udcbe Example Dataframe","text":"iuropa_referral_question_id question_text potential_citations REF_2007_0522DE_Q001 Is additional note 5(b) to Chapter 20 of the Combined Nomenclature (1) to be interpreted as meaning that the term \u2018fruit\u2026 31987R2658,annex I,note 5 point (a) 31987R2658,annex I,note 5 point (b) REF_2007_0522DE_Q002 Is additional note 5(b) to Chapter 20 of the Combined Nomenclature to be interpreted as meaning that the term \u2018fruit jui\u2026 31987R2658,annex I,note 5 point (a) 31987R2658,annex I,note 5 point (b) REF_2007_0522DE_Q003 If both the preceding questions are answered in the affirmative, is additional note 5(b) to Chapter 20 of the Combined N\u2026 31987R2658,annex I,note 5 point (a) 31987R2658,annex I,note 5 point (b) REF_2008_0022DE_Q001 Is Article 24(2) of Directive 2004/38 of the European Parliament and of the Council of 29 April 2004 (1) compatible with\u2026 32004L0038,main,body article 24 paragraph 2 32004L0038,main,body article 6 12006E012,main,body article 12 12006E039,main,body article 39 REF_2008_0039DE_Q003 If the answer is \u2018yes\u2019, is the national court required to take account of the prohibition of discrimination having the e\u2026 31989L0104,main,body article 3"}]}